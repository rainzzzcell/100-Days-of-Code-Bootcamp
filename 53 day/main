from bs4 import BeautifulSoup
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
import time

# Set up headers for the request
header = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36",
    "Accept-Language": "en-GB,en-US;q=0.9,en;q=0.8"
}

# Make a request to the website
response = requests.get("https://appbrewery.github.io/Zillow-Clone/", headers=header)
data = response.text

# Parse the HTML with BeautifulSoup
soup = BeautifulSoup(data, "html.parser")

# Extract links to individual listings
all_link_elements = soup.select(".StyledPropertyCardDataWrapper a")
all_links = ["https://appbrewery.github.io" + link["href"] for link in all_link_elements]  # Add base URL if needed
print(f"There are {len(all_links)} links to individual listings in total:\n")
print(all_links)

# Extract prices of the listings
all_prices_elements = soup.select(".PropertyCardWrapper span")
all_prices = [price.get_text().replace("/mo", "").split("+")[0] for price in all_prices_elements if "$" in price.text]
print(f"\nAfter having been cleaned up, the {len(all_prices)} prices now look like this:\n")
print(all_prices)

# Extract addresses of the listings
all_address_elements = soup.select(".StyledPropertyCardDataWrapper address")
all_addresses = [address.get_text().replace(" | ", " ").strip() for address in all_address_elements]
print(f"\nAfter having been cleaned up, the {len(all_addresses)} addresses now look like this:\n")
print(all_addresses)

# Set up Selenium WebDriver options
chrome_options = webdriver.ChromeOptions()
chrome_options.add_experimental_option("detach", True)

# Uncomment the next line if you want the browser to run headless (without opening a window)
# chrome_options.add_argument("--headless")

driver = webdriver.Chrome(options=chrome_options)

# Loop through the data and fill out the form
for n in range(len(all_links)):
    driver.get("https://docs.google.com/forms/d/e/1FAIpQLScFut-x0vHroo2oBHf6BFYeQZsu03bhnWBWHfQfrxV3yUgA0Q/viewform?usp=sf_link")
    time.sleep(2)

    address = driver.find_element(By.XPATH, value='//*[@id="mG61Hd"]/div[2]/div/div[2]/div[1]/div/div/div[2]/div/div[1]/div/div[1]/input')
    price = driver.find_element(By.XPATH, value='//*[@id="mG61Hd"]/div[2]/div/div[2]/div[2]/div/div/div[2]/div/div[1]/div/div[1]/input')
    link = driver.find_element(By.XPATH, value='//*[@id="mG61Hd"]/div[2]/div/div[2]/div[3]/div/div/div[2]/div/div[1]/div/div[1]/input')
    submit_button = driver.find_element(By.XPATH, value='//*[@id="mG61Hd"]/div[2]/div/div[3]/div[1]/div[1]/div/span')

    address.send_keys(all_addresses[n])
    price.send_keys(all_prices[n])
    link.send_keys(all_links[n])
    submit_button.click()

    time.sleep(2)  # Wait for the form to submit before moving to the next one

# Close the browser once done
driver.quit()
